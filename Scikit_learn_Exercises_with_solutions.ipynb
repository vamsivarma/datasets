{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-learn Exercises with solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+rK+P3AUuyArqfxeb1SIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsivarma/datasets/blob/master/Scikit_learn_Exercises_with_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b36xEEI9o6nb",
        "colab_type": "text"
      },
      "source": [
        "#### For the exercises we will use **Iris flower dataset**\n",
        "\n",
        "#### The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoEjyts24zTu",
        "colab_type": "text"
      },
      "source": [
        "#### Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0hMshdz4yZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numpy for numerical analysis\n",
        "import numpy as np\n",
        "\n",
        "# Pandas for reading and exploring dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Matplotlib for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For showing learning metrics  \n",
        "from sklearn import metrics\n",
        "\n",
        "# For all the metrics\n",
        "\n",
        "# MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# For accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# For splitting input data in to train and test dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For importing methods related to preprocessinng\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Importing scikit-learn algorithms\n",
        "\n",
        "# Linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# SVM\n",
        "\n",
        "# NB\n",
        "\n",
        "# PCA\n",
        "\n",
        "# KMEANS\n",
        "\n",
        "# Decision tree\n",
        "\n",
        "# Random forest\n",
        "\n",
        "# Gradient boosting\n",
        "\n",
        "# XGBoost\n",
        "\n",
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feTTmaiV45rQ",
        "colab_type": "text"
      },
      "source": [
        "#### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2DJTOFL4-IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = pd.read_csv(\"https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/iris/iris_orig.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6HQzgyYpU4q",
        "colab_type": "text"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOF3yLAUpbDF",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1**: Write a Python program to split the iris dataset into its attributes (X) and labels (y). The X variable contains the first four columns (i.e. attributes) and y contains the labels of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEdPqDgqfro4",
        "colab_type": "code",
        "outputId": "c6830a48-e979-40dd-8b3d-429b1902b3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Exercise 1 solution\n",
        "# All rows except last column\n",
        "X = iris.iloc[:, :-1].values\n",
        "\n",
        "# Only 5th column\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "\n",
        "print(iris.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(\"Attributes:\")\n",
        "print(X)\n",
        "print(\"\\nLabels:\")\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 5)\n",
            "(150, 4)\n",
            "(150,)\n",
            "Attributes:\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "\n",
            "Labels:\n",
            "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUrDXLRPsxJF",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2**: Write a Python program using Scikit-learn to split the iris dataset into 70% train data and 30% test data. Out of total 150 records, the training set will contain 120 records and the test set contains 30 of those records. Print both datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX0j8gqms4Gk",
        "colab_type": "code",
        "outputId": "dd4d0b76-a7ab-4099-dfa0-1b8777d582e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Exercise 2 solution\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "#Split arrays or matrices into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "print(\"\\n70% train data:\")\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(\"\\n30% test data:\")\n",
        "print(X_test)\n",
        "print(y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "70% train data:\n",
            "[[5.4 3.4 1.7 0.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.6 3.  4.1 1.3]]\n",
            "['setosa' 'virginica' 'versicolor' 'virginica' 'virginica' 'virginica'\n",
            " 'setosa' 'versicolor' 'versicolor' 'setosa' 'setosa' 'setosa'\n",
            " 'versicolor' 'virginica' 'virginica' 'setosa' 'virginica' 'setosa'\n",
            " 'setosa' 'versicolor' 'versicolor' 'virginica' 'virginica' 'versicolor'\n",
            " 'versicolor' 'setosa' 'versicolor' 'versicolor' 'setosa' 'virginica'\n",
            " 'virginica' 'virginica' 'versicolor' 'setosa' 'virginica' 'setosa'\n",
            " 'versicolor' 'versicolor' 'setosa' 'versicolor' 'virginica' 'virginica'\n",
            " 'versicolor' 'virginica' 'setosa' 'versicolor' 'setosa' 'setosa'\n",
            " 'versicolor' 'setosa' 'setosa' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
            " 'setosa' 'virginica' 'setosa' 'versicolor' 'virginica' 'versicolor'\n",
            " 'setosa' 'virginica' 'virginica' 'virginica' 'versicolor' 'virginica'\n",
            " 'virginica' 'versicolor' 'virginica' 'virginica' 'setosa' 'virginica'\n",
            " 'virginica' 'virginica' 'setosa' 'virginica' 'versicolor' 'virginica'\n",
            " 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'virginica'\n",
            " 'setosa' 'versicolor' 'virginica' 'setosa' 'setosa' 'versicolor' 'setosa'\n",
            " 'virginica' 'versicolor' 'setosa' 'versicolor' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'virginica' 'setosa' 'setosa' 'versicolor']\n",
            "\n",
            "30% test data:\n",
            "[[6.3 3.4 5.6 2.4]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.  2.2 5.  1.5]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.6 2.5 3.9 1.1]]\n",
            "['virginica' 'virginica' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
            " 'versicolor' 'versicolor' 'virginica' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'virginica' 'setosa' 'versicolor' 'setosa' 'virginica'\n",
            " 'setosa' 'versicolor' 'versicolor' 'virginica' 'versicolor' 'versicolor'\n",
            " 'virginica' 'virginica' 'setosa' 'virginica' 'versicolor' 'setosa'\n",
            " 'setosa' 'virginica' 'versicolor' 'setosa' 'versicolor' 'setosa'\n",
            " 'virginica' 'virginica' 'setosa' 'versicolor' 'setosa' 'versicolor'\n",
            " 'virginica' 'virginica' 'versicolor' 'versicolor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FSz4PLn34xR",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 3**: Write a Python program using Scikit-learn to convert Species columns in a numerical column of the iris dataframe. To encode this data map convert each value to a number. e.g. Iris-setosa:0, Iris-versicolor:1, and Iris-virginica:2. Now print the iris dataset into 80% train data and 20% test data. Out of total 150 records, the training set will contain 120 records and the test set contains 30 of those records. Print both datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK-1L2xY35EM",
        "colab_type": "code",
        "outputId": "5f2d4c80-6a64-4a1a-9251-4f29c0577c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Exercise 3 solution\n",
        "\n",
        "# Printing the colums of the dataset to find out column to be tranformed\n",
        "print(iris.columns)\n",
        " \n",
        "# Creating labelEncoder from preprocessing module \n",
        "le = preprocessing.LabelEncoder()\n",
        "# Converting string labels into numbers.\n",
        "iris.species = le.fit_transform(iris.species)\n",
        "\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "#Split arrays or matrices into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "print(\"\\n 80% train data:\")\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "print(\"\\n 20% test data:\")\n",
        "print(X_test)\n",
        "print(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
            "       'species'],\n",
            "      dtype='object')\n",
            "\n",
            "80% train data:\n",
            "[[6.7 2.5 5.8 1.8]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [6.7 3.  5.  1.7]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [7.3 2.9 6.3 1.8]]\n",
            "[2 2 2 0 0 0 1 1 2 0 0 1 0 0 0 0 2 1 1 2 1 2 0 2 1 0 0 2 1 2 2 2 1 1 1 1 1\n",
            " 2 0 2 2 1 0 2 1 1 1 2 1 2 0 0 1 1 1 2 2 0 0 0 2 1 0 1 1 2 2 1 0 2 2 1 0 1\n",
            " 1 1 0 1 1 2 0 0 0 2 2 1 2 0 0 1 0 0 2 1 2 1 0 2 2 0 2 2 2 0 1 2 1 1 0 2 0\n",
            " 2 1 2 2 0 1 0 0 2]\n",
            "\n",
            "20% test data:\n",
            "[[6.9 3.1 5.4 2.1]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [6.4 2.8 5.6 2.2]]\n",
            "[2 1 0 2 1 0 2 2 0 1 1 1 0 0 0 2 0 0 0 0 0 2 1 1 1 0 1 1 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLAk4pkX6TAd",
        "colab_type": "text"
      },
      "source": [
        "###### **Exercise 4**: Write a Python program using Scikit-learn to split the iris dataset into 70% train data and 30% test data. Out of total 150 records, the training set will contain 105 records and the test set contains 45 of those records. Predict the response for test dataset (SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm) using the K Nearest Neighbor Algorithm. Use 5 as number of neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTVyIp-I6YI-",
        "colab_type": "code",
        "outputId": "54212395-6a21-42e4-ef7f-6e675c002347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Exercise 4 solution\n",
        "\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "#Split arrays or matrices into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "\n",
        "#Create KNN Classifier\n",
        "#Number of neighbors to use by default for kneighbors queries.\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "#Train the model using the training sets\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "print(\"Response for test dataset:\")\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Response for test dataset:\n",
            "['versicolor' 'versicolor' 'setosa' 'virginica' 'setosa' 'virginica'\n",
            " 'virginica' 'setosa' 'setosa' 'versicolor' 'setosa' 'virginica' 'setosa'\n",
            " 'virginica' 'setosa' 'setosa' 'virginica' 'virginica' 'versicolor'\n",
            " 'setosa' 'virginica' 'versicolor' 'virginica' 'versicolor' 'virginica'\n",
            " 'virginica' 'versicolor' 'versicolor' 'setosa' 'setosa' 'virginica'\n",
            " 'versicolor' 'setosa' 'versicolor' 'virginica' 'virginica' 'versicolor'\n",
            " 'setosa' 'setosa' 'virginica' 'setosa' 'versicolor' 'virginica'\n",
            " 'versicolor' 'versicolor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxLwvY9d7oBl",
        "colab_type": "text"
      },
      "source": [
        "##### **Exercise 5**: Write a Python program using Scikit-learn to split the iris dataset into 80% train data and 20% test data. Out of total 150 records, the training set will contain 120 records and the test set contains 30 of those records. Train or fit the data into the model and calculate the accuracy of the model using the K Nearest Neighbor Algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjeU0I917r0k",
        "colab_type": "code",
        "outputId": "25fa05a9-25bd-400e-e9a2-ec374bfee5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Exercise 5 solution:\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "#Split arrays or matrices into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) \n",
        "knn = KNeighborsClassifier(n_neighbors=5)  \n",
        "knn.fit(X_train, y_train)   \n",
        "\n",
        "# Calculate the accuracy of the model \n",
        "print(\"Accuracy of the model:\")\n",
        "print(knn.score(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model:\n",
            "0.9777777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpmizy-q8VIP",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 6**: Write a Python program using Scikit-learn to split the iris dataset into 80% train data and 20% test data. Out of total 150 records, the training set will contain 120 records and the test set contains 30 of those records. Train or fit the data into the model and using the K Nearest Neighbor Algorithm calculate the performance for different values of k "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brPkYgNY8VZX",
        "colab_type": "code",
        "outputId": "501459f0-0596-484d-c19f-53017cb36d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Exercise 6 solution\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "#Split arrays or matrices into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
        "knn = KNeighborsClassifier(n_neighbors=7)  \n",
        "knn.fit(X_train, y_train) \n",
        "  \n",
        "# Calculate the accuracy of the model for different values of k\n",
        "for i in np.arange(1, 10):\n",
        "    knn2 = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn2.fit(X_train, y_train)\n",
        "    print(\"For k = %d accuracy is\"%i,knn2.score(X_test,y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For k = 1 accuracy is 0.9666666666666667\n",
            "For k = 2 accuracy is 0.9333333333333333\n",
            "For k = 3 accuracy is 0.9666666666666667\n",
            "For k = 4 accuracy is 0.9333333333333333\n",
            "For k = 5 accuracy is 0.9333333333333333\n",
            "For k = 6 accuracy is 0.9\n",
            "For k = 7 accuracy is 0.9333333333333333\n",
            "For k = 8 accuracy is 0.9\n",
            "For k = 9 accuracy is 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGhff_1N9cZy",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 7**: Write a Python program using Scikit-learn to split the iris dataset into 80% train data and 20% test data. Out of total 150 records, the training set will contain 120 records and the test set contains 30 of those records. Train or fit the data into the model and using the K Nearest Neighbor Algorithm and create a plot to present the performance for different values of k. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUPeJKkq97Q6",
        "colab_type": "code",
        "outputId": "b8edeeb4-e61f-4f6f-b700-4ad6f8344ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "# Exercise 7 solution\n",
        "\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "#Split arrays or matrices into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
        "knn = KNeighborsClassifier(n_neighbors=7)  \n",
        "knn.fit(X_train, y_train)   \n",
        "a_index=list(range(1,11))\n",
        "a=pd.Series()\n",
        "# Calculate the accuracy of the model for different values of k\n",
        "for i in np.arange(1, 10):\n",
        "    knn2 = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn2.fit(X_train, y_train)\n",
        "    print(\"For k = %d accuracy is\"%i,knn2.score(X_test,y_test))\n",
        "# Visual presentation: Various values of n for K-Nearest nerighbours\n",
        "print(\"\\nVisual presentation: Various values of n for K-Nearest nerighbours:\")    \n",
        "for i in list(range(1,11)):\n",
        "    model=KNeighborsClassifier(n_neighbors=i) \n",
        "    model.fit(X_train,y_train)\n",
        "    prediction=model.predict(X_test)\n",
        "    a=a.append(pd.Series(metrics.accuracy_score(prediction,y_test)))\n",
        "plt.plot(a_index, a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For k = 1 accuracy is 0.9333333333333333\n",
            "For k = 2 accuracy is 0.9\n",
            "For k = 3 accuracy is 0.9666666666666667\n",
            "For k = 4 accuracy is 0.9666666666666667\n",
            "For k = 5 accuracy is 0.9666666666666667\n",
            "For k = 6 accuracy is 0.9666666666666667\n",
            "For k = 7 accuracy is 0.9666666666666667\n",
            "For k = 8 accuracy is 0.9666666666666667\n",
            "For k = 9 accuracy is 0.9666666666666667\n",
            "\n",
            "Visual presentation: Various values of n for K-Nearest nerighbours:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feffe046ba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_0i-iukCYk2",
        "colab_type": "text"
      },
      "source": [
        "Exercises related to Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1NmDUmCCdb9",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 8**: Write a Python program to view some basic statistical details like percentile, mean, std etc. of the species of 'Iris-setosa', 'Iris-versicolor' and 'Iris-versicolor'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtakiBdMCgzr",
        "colab_type": "code",
        "outputId": "635266cf-0702-4a99-c85f-d5245648c907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "print('Iris-setosa')\n",
        "setosa = iris['species'] == 'setosa'\n",
        "print(iris[setosa].describe())\n",
        "print('\\n Iris-versicolor')\n",
        "setosa = iris['species'] == 'versicolor'\n",
        "print(iris[setosa].describe())\n",
        "print('\\n Iris-virginica')\n",
        "setosa = iris['species'] == 'virginica'\n",
        "print(iris[setosa].describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iris-setosa\n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count      50.00000    50.000000     50.000000    50.000000\n",
            "mean        5.00600     3.428000      1.462000     0.246000\n",
            "std         0.35249     0.379064      0.173664     0.105386\n",
            "min         4.30000     2.300000      1.000000     0.100000\n",
            "25%         4.80000     3.200000      1.400000     0.200000\n",
            "50%         5.00000     3.400000      1.500000     0.200000\n",
            "75%         5.20000     3.675000      1.575000     0.300000\n",
            "max         5.80000     4.400000      1.900000     0.600000\n",
            "\n",
            " Iris-versicolor\n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count     50.000000    50.000000     50.000000    50.000000\n",
            "mean       5.936000     2.770000      4.260000     1.326000\n",
            "std        0.516171     0.313798      0.469911     0.197753\n",
            "min        4.900000     2.000000      3.000000     1.000000\n",
            "25%        5.600000     2.525000      4.000000     1.200000\n",
            "50%        5.900000     2.800000      4.350000     1.300000\n",
            "75%        6.300000     3.000000      4.600000     1.500000\n",
            "max        7.000000     3.400000      5.100000     1.800000\n",
            "\n",
            " Iris-virginica\n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count      50.00000    50.000000     50.000000     50.00000\n",
            "mean        6.58800     2.974000      5.552000      2.02600\n",
            "std         0.63588     0.322497      0.551895      0.27465\n",
            "min         4.90000     2.200000      4.500000      1.40000\n",
            "25%         6.22500     2.800000      5.100000      1.80000\n",
            "50%         6.50000     3.000000      5.550000      2.00000\n",
            "75%         6.90000     3.175000      5.875000      2.30000\n",
            "max         7.90000     3.800000      6.900000      2.50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of7i7MI1DaYX",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 9**: Write a Python program to create a scatter plot using sepal length and petal_width to separate the Species classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7YTNAB7Dq7C",
        "colab_type": "code",
        "outputId": "8ce96cca-a04e-43af-a1b4-6c6accf346f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Exercise 9 solution\n",
        "\n",
        "#Convert Species columns in a numerical column of the iris dataframe\n",
        "#creating labelEncoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Converting string labels into numbers.\n",
        "iris.species = le.fit_transform(iris.species)\n",
        "x = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "plt.scatter(x[:,0], x[:, 3], c=y, cmap ='flag')\n",
        "plt.xlabel('Sepal Length cm')\n",
        "plt.ylabel('Petal Width cm')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBLtOFyvD1Qz",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 10**: Write a Python program to get the accuracy of the Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhOSN5LHD1vC",
        "colab_type": "code",
        "outputId": "fbfdc04d-3efb-4e7e-e56e-dd57ba33ed46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "#Split arrays or matrices into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40) \n",
        "\n",
        "model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X, y)\n",
        "model.fit(X_train,y_train)\n",
        "prediction=model.predict(X_test)\n",
        "print('The accuracy of the Logistic Regression is', metrics.accuracy_score(prediction,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the Logistic Regression is 0.9333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-CKMgDlEjbQ",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 11**: Apply Linear regression on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVdLjMmzEjum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez8MOaYfExBS",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 12**: Apply SVM on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZrmYgQZExTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnLj_xvwEkAm",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 13**: Apply Naive Bayes on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WZoyPPFEkOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOxQ1XvzFASj",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 14**: Apply PCA on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bl8n_IHFAiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zxZQ2qLFLmX",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 15**: Apply K-means on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niHUEhQEFL6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEos6YOPF1ii",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 16**: Apply Decision tree on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkwy7SXxF14f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYJ1t8ThGEzi",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 17**: Apply Random forest on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdHCMCkWGFRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adEdq-ISF2HM",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 18**: Apply Gradient boosting on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIg7R3U0F2Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5veFAeTqGR1S",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 19**: Apply XGBoost on Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aMWDQ1OGSEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOpQ9jS4FSSb",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 20**: Find accuracy score for all the algorithms (Linear regression, Logistic regression, SVM, Decision tree etc..,) mentioned above and compare them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsVW5fFXFSi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEtjRR0HGrQK",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 21**: Find classification report score for all the algorithms (Linear regression, Logistic regression, SVM, Decision tree etc..,) mentioned above and compare them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMsbRQzEGrib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZjTzfrvGxaW",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 22**: Find confusion matrix for all the classification algorithms (Logistic regression, SVM, Decision tree etc..,) mentioned above and compare them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSqSlwhyGx1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UunHMvUOHEli",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 23**: Find MSE - mean squared error and MAE - mean absolute error, R2 score for the regression algorithms (Linear regression, Random forest etc..,) mentioned above and compare them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFSDqTKVHFCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odijdXmgHyBg",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 24**: Find adjusted rand index for all the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKBqUEH3Hz5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ3s7BQWH0Rk",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 25**: Find Homogenity for all the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdTCgCMnH0kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgum_VYPIJbH",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 26**: Find V-measure for all the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsmMT3mhIJzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIOcYyqLIQz5",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 27**: Try to apply data normalization and data standardization for Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6LhOCKpIRE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6lGZWuJIeZX",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 28**: Try to apply L1 & L2 regularization for Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tDV0g5LIesa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uf1qLkbImT_",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 29**: Try to find Precision and Recall for Iris dataset for different algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5wNMs-FImmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg21Igf7I3cu",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 30**: Try to find AUC for Iris dataset for different algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_m79C2GI3u8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PBmgg4xI-7J",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 31**: Try to find cost sensitive accuracy for Iris dataset for different algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg-LMhLbI_K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B19PNFzuJJj0",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 32**: Apply grid search for Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Eed07RJJ2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coei0WqxJSuQ",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 33**: Apply random search for Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWWK5pArJTfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gibSQpoHJckn",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 34**: Apply model tuning Bayesian techniques for Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXY7grqBJc8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMHYfxFLfxUK",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "https://www.w3resource.com/machine-learning/scikit-learn/iris/index.php"
      ]
    }
  ]
}